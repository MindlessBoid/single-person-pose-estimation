{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gen_tfrecords.ipynb","provenance":[],"mount_file_id":"1QNsfoB7PBdhwxdwMBKSR3HAXjWMEk-lp","authorship_tag":"ABX9TyPqfsKsMVNZEsyXsfpYwK7E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"73XbDhvMJALC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8f2c153c-7a0b-4caf-ffc1-0f7aec6131e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Getting train2017\n","--2022-03-18 02:12:44--  http://images.cocodataset.org/zips/train2017.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.65.48\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.65.48|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19336861798 (18G) [application/zip]\n","Saving to: ‘train2017.zip’\n","\n","train2017.zip         6%[>                   ]   1.21G  45.1MB/s    eta 6m 29s "]}],"source":["!bash /content/drive/MyDrive/single-person-pose-estimation/dataset/get_data.sh"]},{"cell_type":"code","source":["import time\n","from datetime import datetime, timedelta\n","import sys"],"metadata":{"id":"dhvA7Ko3Jjkt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sys.path.append('/content/drive/MyDrive/single-person-pose-estimation')"],"metadata":{"id":"0okAJo8WJuj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from configs import default_config as cfg\n","from coco_df import gen_trainval_df\n","from gen_tfrecords import gen_TFRecords"],"metadata":{"id":"rEqMPADHJ8Ky"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df, valid_df = gen_trainval_df(cfg)"],"metadata":{"id":"EkrchOLoKY_t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = time.time()\n","gen_TFRecords(train_df, cfg, is_train = True)\n","total_time = time.time() - start\n","print(\"Total time: {}\".format(str(timedelta(seconds=total_time))))"],"metadata":{"id":"PB3iaNZfJ5Ix"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = time.time()\n","gen_TFRecords(valid_df, cfg, is_train = False)\n","total_time = time.time() - start\n","print(\"Total time: {}\".format(str(timedelta(seconds=total_time))))"],"metadata":{"id":"hvJAxHEXKVbW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check size, good size per file ~100Mb\n","!ls -lh \"dataset/tfrecords/train\" \n","!ls -lh \"dataset/tfrecords/valid\" "],"metadata":{"id":"NbmsJXNzMFz-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n","Just testing"],"metadata":{"id":"DcyMVpIxNNLM"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import tensorflow as tf"],"metadata":{"id":"dYKZYyLWNQfs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### For reading\n","def parse_tfrecord_fn(example):\n","    feature_description = {\n","        \"ann_id\": tf.io.FixedLenFeature([], tf.int64),\n","        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"image_path\": tf.io.FixedLenFeature([], tf.string),\n","        \"width\": tf.io.FixedLenFeature([], tf.int64),\n","        \"height\": tf.io.FixedLenFeature([], tf.int64),\n","        \"keypoints/x\": tf.io.VarLenFeature(tf.float32),\n","        \"keypoints/y\": tf.io.VarLenFeature(tf.float32),\n","        \"keypoints/vis\": tf.io.VarLenFeature(tf.int64),\n","        \"keypoints/num\": tf.io.FixedLenFeature([], tf.int64)\n","    }\n","    \n","    example = tf.io.parse_single_example(example, feature_description)\n","    example[\"image\"] = tf.image.decode_image(example[\"image\"], channels = 3, dtype = tf.float32, expand_animations =False)\n","    example[\"keypoints/x\"] = tf.sparse.to_dense(example[\"keypoints/x\"])\n","    example[\"keypoints/y\"] = tf.sparse.to_dense(example[\"keypoints/y\"])\n","    example[\"keypoints/vis\"] = tf.sparse.to_dense(example[\"keypoints/vis\"])\n","    return example\n","  ### example\n","def gen_examples_from_tfrecord(filepath, example_num):\n","  raw_dataset = tf.data.TFRecordDataset(filepath)\n","  parsed_dataset = raw_dataset.map(parse_tfrecord_fn)\n","  for example in parsed_dataset.take(example_num):\n","      for key in example.keys():\n","          if key != \"image\":\n","              print(f\"{key}: {example[key]}\")\n","\n","      xcoords = example[\"keypoints/x\"].numpy()\n","      ycoords = example[\"keypoints/y\"].numpy()\n","      image = example[\"image\"]\n","      h, w, c = image.shape\n","      print(f\"Image shape: {image.shape}\")\n","      plt.figure(figsize=(7, 7))\n","  \n","      plt.imshow(image)\n","      plt.scatter(xcoords  , ycoords  , marker = \"o\") # for heatmap size\n","      plt.show()  "],"metadata":{"id":"QjxjdbtnMiIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gen_examples_from_tfrecord('dataset/tfrecords/valid/file_valid_00-2048.tfrec', 10)"],"metadata":{"id":"unQ8KCUHMuhA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n","IF run on local machine skip the following"],"metadata":{"id":"wImVPRT0MCEd"}},{"cell_type":"code","source":["!zip -r 'dataset/tfrecords.zip' 'dataset/tfrecords'"],"metadata":{"id":"O1d72UuYMRCW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp 'dataset/tfrecords.zip' 'drive/MyDrive/single-person-pose-estimation/dataset'"],"metadata":{"id":"S03RZwU4MYal"},"execution_count":null,"outputs":[]}]}